{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8b4af00-7155-4561-bc23-2c839a917473",
   "metadata": {},
   "source": [
    "## RandomForest_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2fd04-c92e-4f6a-acf3-fdc2cf28976f",
   "metadata": {},
   "source": [
    "### What is ‚ÄúFeature Importance‚Äù in Random Forests?\n",
    "\n",
    "When you train a random forest, it tries to figure out which features (columns in your dataset) are more useful for making predictions.\n",
    "\n",
    "Some features help the model a lot.\n",
    "\n",
    "Some features add very little value.\n",
    "\n",
    "The model gives a score to each feature, showing how important it is.\n",
    "\n",
    "üè† Real-life example\n",
    "\n",
    "Imagine you‚Äôre predicting house prices with these features:\n",
    "\n",
    "üè† Size of house (sq. ft.)\n",
    "\n",
    "üìç Location\n",
    "\n",
    "üõãÔ∏è Number of rooms\n",
    "\n",
    "üöó Parking availability\n",
    "\n",
    "üé® Paint color of walls\n",
    "\n",
    "After training a Random Forest, feature importance might look like:\n",
    "\n",
    "Location ‚Üí 50%\n",
    "\n",
    "Size ‚Üí 30%\n",
    "\n",
    "Rooms ‚Üí 15%\n",
    "\n",
    "Parking ‚Üí 5%\n",
    "\n",
    "Paint color ‚Üí 0%\n",
    "\n",
    "üëâ This means:\n",
    "\n",
    "Location and Size are the biggest factors in predicting house prices.\n",
    "\n",
    "Paint color doesn‚Äôt really matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a34b51-efe1-45b6-b21c-00b78ce94d51",
   "metadata": {},
   "source": [
    "### ‚úÖ In short: Feature importance tells us which factors really drive the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421fef07-baa8-4299-b077-be61a1a1fcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0.45\n",
      "pclass: 0.16\n",
      "sex_male: 0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/bfj9nybj02jf94xlvrjnp9nr0000gn/T/ipykernel_2126/1453066092.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
      "/var/folders/rx/bfj9nybj02jf94xlvrjnp9nr0000gn/T/ipykernel_2126/1453066092.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load Titanic dataset (from seaborn for simplicity)\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Select useful columns\n",
    "X = titanic[[\"age\", \"sex\", \"pclass\"]]\n",
    "y = titanic[\"survived\"]\n",
    "\n",
    "# Handle missing values\n",
    "X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
    "\n",
    "# Convert categorical (sex) ‚Üí numeric\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Show results\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f\"{feature}: {importance:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e632810-4a82-417c-a5c9-6f52995f8656",
   "metadata": {},
   "source": [
    "### üå≥ Random Forest has many knobs we can adjust\n",
    "\n",
    "These knobs are called hyperparameters (settings you choose before training).\n",
    "The two most important ones are:\n",
    "\n",
    "1. n_estimators ‚Üí Number of trees üå≤üå≤üå≤\n",
    "\n",
    "Think of it like a voting team.\n",
    "\n",
    "More trees = more stable, accurate predictions.\n",
    "\n",
    "But more trees = slower training.\n",
    "\n",
    "üëâ Example:\n",
    "\n",
    "n_estimators=10 ‚Üí only 10 trees (fast but maybe less accurate).\n",
    "\n",
    "n_estimators=200 ‚Üí 200 trees (more accurate, but slower).\n",
    "\n",
    "2. max_depth ‚Üí How deep each tree can grow\n",
    "\n",
    "A deep tree memorizes the training data (can overfit).\n",
    "\n",
    "A shallow tree may miss patterns (can underfit).\n",
    "\n",
    "üëâ Example:\n",
    "\n",
    "max_depth=2 ‚Üí tree makes very simple rules (may be too simple).\n",
    "\n",
    "max_depth=None ‚Üí tree can grow fully (may overfit).\n",
    "\n",
    "üéØ Goal of tuning\n",
    "\n",
    "Find the sweet spot where model is:\n",
    "\n",
    "Accurate on training data ‚úÖ\n",
    "\n",
    "Also works well on unseen test data ‚úÖ\n",
    "\n",
    "üëâ Example analogy:\n",
    "\n",
    "n_estimators = number of judges in a contest.\n",
    "\n",
    "max_depth = how detailed each judge‚Äôs checklist is.\n",
    "Too many judges with too deep checklists ‚Üí slow & confusing.\n",
    "Too few judges with too short checklists ‚Üí unfair decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4a0d1e8-ad08-468f-b3ef-c576d72d5081",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/bfj9nybj02jf94xlvrjnp9nr0000gn/T/ipykernel_2126/580189319.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
      "/var/folders/rx/bfj9nybj02jf94xlvrjnp9nr0000gn/T/ipykernel_2126/580189319.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees=10, Depth=3, Accuracy=0.817\n",
      "Trees=10, Depth=5, Accuracy=0.802\n",
      "Trees=10, Depth=None, Accuracy=0.780\n",
      "Trees=50, Depth=3, Accuracy=0.802\n",
      "Trees=50, Depth=5, Accuracy=0.810\n",
      "Trees=50, Depth=None, Accuracy=0.791\n",
      "Trees=100, Depth=3, Accuracy=0.791\n",
      "Trees=100, Depth=5, Accuracy=0.806\n",
      "Trees=100, Depth=None, Accuracy=0.787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load Titanic dataset from seaborn (or local CSV if you have it)\n",
    "import seaborn as sns\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "\n",
    "# Select useful columns\n",
    "X = titanic[[\"pclass\", \"sex\", \"age\", \"fare\"]]\n",
    "y = titanic[\"survived\"]\n",
    "\n",
    "# Handle missing values\n",
    "X[\"age\"].fillna(X[\"age\"].median(), inplace=True)\n",
    "\n",
    "# Convert categorical (sex) ‚Üí numeric\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "for n in [10, 50, 100]:\n",
    "    for depth in [3, 5, None]:\n",
    "        model = RandomForestClassifier(n_estimators=n, max_depth=depth, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Trees={n}, Depth={depth}, Accuracy={acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670f28a1-f156-4e46-8e71-cd4b8c5acdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.806\n",
      "\n",
      "Feature Importance:\n",
      "pclass: 0.159\n",
      "age: 0.158\n",
      "fare: 0.220\n",
      "sex_male: 0.463\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", round(acc, 3))\n",
    "\n",
    "# Feature Importance\n",
    "importances = model.feature_importances_\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "for feature, importance in zip(X.columns, importances):\n",
    "    print(f\"{feature}: {importance:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca2422-14a9-4d20-8435-a147ab48070b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
